{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e44a92f4",
   "metadata": {},
   "source": [
    "# CIS 9660 – Project #2, Question #3\n",
    "**Unsupervised Learning: Customer Segmentation + Association Rule Mining**\n",
    "\n",
    "**Dataset:** TidyTuesday — Hotels (bookings) (public CSV)\n",
    "\n",
    "**Pipeline:**\n",
    "1. Load public dataset directly from URL\n",
    "2. Clean & select features\n",
    "3. **K-Means** clustering with **Elbow** & **Silhouette** to choose K\n",
    "4. **Gaussian Mixture** (GMM) as alternative clustering with **BIC**\n",
    "5. **PCA (2D)** visualization of K-Means clusters\n",
    "6. **Apriori** association rules over categorical booking attributes\n",
    "7. Save key outputs (CSV figures/metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab5e301",
   "metadata": {},
   "source": [
    "## 0) Setup (Installs for Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a9c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If running in Google Colab, run this cell once\n",
    "!pip -q install mlxtend plotly scikit-learn pandas matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0353e7b6",
   "metadata": {},
   "source": [
    "## 1) Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf0b928",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.1)\n",
    "RANDOM_STATE = 42\n",
    "plt.rcParams['figure.figsize'] = (8,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1042cffe",
   "metadata": {},
   "source": [
    "## 2) Load Dataset (TidyTuesday Hotels CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c87338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(\"Raw shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b70f569",
   "metadata": {},
   "source": [
    "## 3) Basic Cleaning & Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a17220",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop rows with missing values in key numeric fields we will use\n",
    "num_cols = [\n",
    "    'lead_time', 'arrival_date_week_number', 'arrival_date_day_of_month',\n",
    "    'stays_in_weekend_nights', 'stays_in_week_nights',\n",
    "    'adults', 'children', 'babies', 'previous_cancellations',\n",
    "    'booking_changes', 'days_in_waiting_list', 'adr', 'total_of_special_requests'\n",
    "]\n",
    "\n",
    "# Some datasets have 'children' as float with NaNs; fill with 0 first then drop rows still missing elsewhere\n",
    "if 'children' in df.columns:\n",
    "    df['children'] = df['children'].fillna(0)\n",
    "\n",
    "# Drop rows with *any* NaNs across selected numeric columns\n",
    "df = df.dropna(subset=num_cols)\n",
    "\n",
    "# Keep a clean numeric matrix\n",
    "X = df[num_cols].copy()\n",
    "\n",
    "print(\"Shape after cleaning:\", df.shape)\n",
    "df[num_cols].describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da342d9",
   "metadata": {},
   "source": [
    "## 4) Standardize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402f5f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e71f7e2",
   "metadata": {},
   "source": [
    "## 5) Choose K: Elbow (Inertia) & Silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821daa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K_range = range(2, 11)\n",
    "\n",
    "# Elbow\n",
    "inertias = []\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init='auto')\n",
    "    km.fit(X_scaled)\n",
    "    inertias.append(km.inertia_)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(K_range), inertias, marker='o')\n",
    "plt.title(\"Elbow Method (K-Means)\")\n",
    "plt.xlabel(\"Number of clusters (K)\")\n",
    "plt.ylabel(\"Inertia (Within-Cluster Sum of Squares)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Silhouette\n",
    "sil_scores = []\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init='auto')\n",
    "    labels = km.fit_predict(X_scaled)\n",
    "    sil_scores.append(silhouette_score(X_scaled, labels))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(K_range), sil_scores, marker='o')\n",
    "plt.title(\"Silhouette Score vs K (K-Means)\")\n",
    "plt.xlabel(\"Number of clusters (K)\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "best_k = list(K_range)[int(np.argmax(sil_scores))]\n",
    "print(\"Best K by silhouette:\", best_k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc8831",
   "metadata": {},
   "source": [
    "## 6) Fit K-Means & Profile Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d579b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=RANDOM_STATE, n_init='auto')\n",
    "df['kmeans_cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "profile_km = df.groupby('kmeans_cluster')[num_cols].mean().round(2)\n",
    "print(\"K-Means Segment Profile (means):\")\n",
    "display(profile_km)\n",
    "\n",
    "# Save profile for appendix\n",
    "profile_km.to_csv('kmeans_segment_profile.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79a8d4d",
   "metadata": {},
   "source": [
    "## 7) Alternative Clustering: Gaussian Mixture (BIC Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0965a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bics = []\n",
    "for k in K_range:\n",
    "    gmm = GaussianMixture(n_components=k, covariance_type='full', random_state=RANDOM_STATE)\n",
    "    gmm.fit(X_scaled)\n",
    "    bics.append(gmm.bic(X_scaled))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(K_range), bics, marker='o')\n",
    "plt.title(\"GMM Model Selection (BIC)\")\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"BIC (lower is better)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "best_gmm_k = list(K_range)[int(np.argmin(bics))]\n",
    "print(\"Best GMM components by BIC:\", best_gmm_k)\n",
    "\n",
    "gmm = GaussianMixture(n_components=best_gmm_k, covariance_type='full', random_state=RANDOM_STATE)\n",
    "df['gmm_cluster'] = gmm.fit_predict(X_scaled)\n",
    "\n",
    "profile_gmm = df.groupby('gmm_cluster')[num_cols].mean().round(2)\n",
    "print(\"GMM Segment Profile (means):\")\n",
    "display(profile_gmm)\n",
    "\n",
    "# Save profile for appendix\n",
    "profile_gmm.to_csv('gmm_segment_profile.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd1f43e",
   "metadata": {},
   "source": [
    "## 8) PCA (2D) Visualization of K-Means Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd85a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "df['pca1'] = X_pca[:, 0]\n",
    "df['pca2'] = X_pca[:, 1]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(\n",
    "    x='pca1', y='pca2',\n",
    "    hue='kmeans_cluster',\n",
    "    palette='viridis',\n",
    "    data=df, alpha=0.7, s=30, edgecolor=None\n",
    ")\n",
    "plt.title('Customer Segmentation (K-Means) in PCA space')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save PCA coordinates (optional)\n",
    "df[['pca1','pca2','kmeans_cluster']].to_csv('pca_kmeans_points.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f1078a",
   "metadata": {},
   "source": [
    "## 9) Market Basket / Association Rules (Apriori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10077504",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We'll use categorical booking attributes as 'items' for one-hot transactions\n",
    "cat_cols = ['hotel', 'meal', 'market_segment', 'distribution_channel', 'reserved_room_type']\n",
    "\n",
    "# Drop rows with missing in these cats (rare) and create one-hot\n",
    "df_rules = df.dropna(subset=cat_cols).copy()\n",
    "basket = pd.get_dummies(df_rules[cat_cols], drop_first=False).astype(int)\n",
    "\n",
    "# Apriori frequent itemsets & association rules\n",
    "freq_itemsets = apriori(basket, min_support=0.05, use_colnames=True)\n",
    "rules = association_rules(freq_itemsets, metric='lift', min_threshold=1.0)\n",
    "\n",
    "# Sort by lift and select key columns\n",
    "rules = rules.sort_values('lift', ascending=False)\n",
    "rules_view = rules[['antecedents','consequents','support','confidence','lift','leverage','conviction']].head(25)\n",
    "print(\"Top association rules (by lift):\")\n",
    "display(rules_view)\n",
    "\n",
    "# Save to CSV for appendix\n",
    "rules.to_csv('association_rules_full.csv', index=False)\n",
    "rules_view.to_csv('association_rules_top25.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78317fdc",
   "metadata": {},
   "source": [
    "## 10) Business Intelligence Notes (Copy into your 1-page report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4904f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\"\"\n",
    "Suggested talking points:\n",
    "\"\n",
    "\"- **K selection**: Used Elbow + Silhouette (K-Means) and BIC (GMM). Report chosen K and the rationale.\n",
    "\"\n",
    "\"- **Segment personas**: Summarize notable differences by cluster (e.g., high lead_time + low adr vs short stays with many special requests).\n",
    "\"\n",
    "\"- **Actions**: Tailored offers per cluster (advance-bookers vs last-minute), upsell packages for long weekday stays, etc.\n",
    "\"\n",
    "\"- **Association rules**: High-lift pairs of booking attributes (e.g., specific meal plan + distribution channel) indicate strong co-occurrence for targeted promos.\n",
    "\"\n",
    "\"- **Limitations**: No price per person or room inventory; adr may be skewed; consider seasonality and event calendars.\n",
    "\"\n",
    "\"- **Future work**: Add time-based features (season/month), incorporate review sentiment, test alternative clustering (DBSCAN/Hierarchical).\n",
    "\"\n",
    "\"\"\"\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
